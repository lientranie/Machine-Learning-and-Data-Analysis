{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mError: The import statement 'import os' cannot be found or cannot be imported. Imported names must end with '.*' or be fully qualified.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Error",
     "evalue": -1,
     "output_type": "error",
     "traceback": "Error: The import statement 'import os' cannot be found or cannot be imported. Imported names must end with '.*' or be fully qualified.\n"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import crc32\n",
    "Colors = ['#004165','#dc4200',  '#69be28', '#f0be00', '#0cc6de', '#bed600', '#006983', '2b580c', '639a67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = pd.read_csv( r'C:\\Users\\tranli\\ColorMagic\\operationviewtable_June05_2019_To_March17_2020.csv')\n",
    "rawdf = rawdf.drop(columns = rawdf.columns.tolist()[0])\n",
    "rawdf.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.hist(bins=50, figsize=(20,15), color = \"darkred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the interested attributes\n",
    "attributes = [\"prop_power_kW\",\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]\n",
    "subdf         = rawdf[attributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and Visualize the Data to Gain Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdf.copy()\n",
    "data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",color = \"darkred\",  alpha=0.1)\n",
    "plt.title(\"Visualization that highlights high-density areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = rawdf.copy()\n",
    "data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "             s=data['prop_power_kW']/1000, label=\"Propulsion\", figsize=(10,7),\n",
    "             c=\"sog_ms\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "             sharex=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General look of the whole data set\n",
    "data          = rawdf.copy()\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"prop_power_kW\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "data = subdf.copy()\n",
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subdf.copy()\n",
    "with plt.style.context(['science', 'ieee', \"grid\"]):\n",
    "    plt.rcParams[\"figure.figsize\"] =  4,2\n",
    "    plt.scatter(data.sog_kn,data.prop_power_kW,  color = Colors[0], s =5,alpha=0.1)\n",
    "    plt.title(\"Speed-Power relation\")\n",
    "    plt.ylabel(\"Propulsion power, kW\")\n",
    "    plt.xlabel(\"Speed over ground, kn\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Data clearning for Machine Learning Algorithms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find Missing Ratio of Dataset \n",
    "data =  subdf.copy()\n",
    "all_data_na = (data.isnull().sum() / len(data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio (%)' :all_data_na})\n",
    "\n",
    "# Percent missing data by feature\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(figsize=(16, 5))\n",
    "plt.xticks()\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"prop_power_kW\",\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]\n",
    "subdf         = rawdf[attributes]\n",
    "#Replacing NaN by the median value\n",
    "for attr in attributes:\n",
    "    rawdf[attr].fillna(rawdf[attr].median(), inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "data = subdf.copy()\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(data)\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(data[attributes])\n",
    "df_transformed = pd.DataFrame(X, columns=attributes,\n",
    "                          index=subdf.index)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data = rawdf.copy()\n",
    "direction = data.voyage_last_port\n",
    "direction =np.array(direction).reshape(-1,1)\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "subdf_dir_encoded = ordinal_encoder.fit_transform(direction)\n",
    "subdf_dir_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "subdf_dir_1hot = cat_encoder.fit_transform(direction)\n",
    "subdf_dir_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displace_error(y_test,pred):\n",
    "    mae =mean_absolute_error(y_test,pred)\n",
    "    mse =mean_squared_error(y_test,pred)\n",
    "    me  = max_error(y_test,pred)\n",
    "    r2  = r2_score(y_test,pred)\n",
    "    error = pd.DataFrame([mae,mse, me, r2], index = [\"mean_absolute_error\", \"mean_squared_error\", \"maximum_error\", \"R2 score\" ], columns =[\"Error\"])\n",
    "    print(error)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = rawdf.copy()\n",
    "\n",
    "features = [\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]  # independent variables \n",
    "\n",
    "X        = data[features].values\n",
    "y        = data[\"prop_power_kW\"].values  # target variable (dependent variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "pred      = LinReg.predict(X_test)\n",
    "\n",
    "lr_error = displace_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing \n",
    "data = rawdf.copy()\n",
    "\n",
    "features = [\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]  # independent variables \n",
    "\n",
    "X        = data[features].values\n",
    "y        = data[\"prop_power_kW\"].values  # target variable (dependent variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "RanForest = RandomForestRegressor(random_state=1, n_estimators=100)\n",
    "RanForest.fit(X_train, y_train)\n",
    "pred      = RanForest.predict(X_test)\n",
    "\n",
    "rf_error = displace_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "data = rawdf.copy()\n",
    "features = [\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]  # independent variables \n",
    "X        = data[features].values\n",
    "y        = data[\"prop_power_kW\"].values  # target variable (dependent variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "pred     = tree_reg.predict(X_test)\n",
    "tr_error = displace_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVR\n",
    "data = rawdf.copy()\n",
    "features = [\"sog_kn\", \"windspeed_ms\",\"waterdepth_m\" , \"trim_m\" ]  # independent variables \n",
    "X        = data[features].values\n",
    "y        = data[\"prop_power_kW\"].values  # target variable (dependent variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svm_reg  = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(X_train, y_train)\n",
    "pred     = svm_reg.predict(X_test)\n",
    "svm_error= displace_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores  = cross_val_score(tree_reg, X_test, y_test,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "# Requirement: which hyperparameters and what values. The Grid search uses cross-validation to evaluate all possible \n",
    "# combinations of hyperparameters values.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    # try 9 (3×3) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (pred - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(squared_errors)\n",
    "mean = squared_errors.mean()\n",
    "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
    "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom, expon\n",
    "geom_distrib=geom(0.5).rvs(10000, random_state=42)\n",
    "expon_distrib=expon(scale=1).rvs(10000, random_state=42)\n",
    "plt.hist(geom_distrib,color=\"darkred\", bins=50)\n",
    "plt.show()\n",
    "plt.hist(expon_distrib,color=\"darkred\", bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a Support Vector Machine regressor (sklearn.svm.SVR), with various hyperparameters such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Don't worry about what these hyperparameters mean for now. How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ]\n",
    "\n",
    "svm_reg = SVR()\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "negative_mse = rnd_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
